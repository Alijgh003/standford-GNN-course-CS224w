{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip install torch-scatter -f $scatter_src\n",
        "!pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric\n",
        "!pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvesJePQi4-N",
        "outputId": "eba8c2fc-9640-485b-da31-8597f1ef9479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu124.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt25cu124\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu124.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt25cu124\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.3.0)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (75.1.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (2025.1.31)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n"
      ],
      "metadata": {
        "id": "ls1bt33Pix4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.NormalizeFeatures(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
        "                      add_negative_train_samples=False),\n",
        "])\n",
        "\n",
        "path = osp.join('.', '..', 'data', 'Planetoid')\n",
        "dataset = Planetoid(path, name='Cora', transform=transform)\n",
        "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
        "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
        "# each element representing the corresponding split.\n",
        "train_data, val_data, test_data = dataset[0]\n",
        "print(f'train_data={train_data}')\n",
        "print(f'val_data={val_data}')\n",
        "print(f'test_data={test_data}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5_Sh_qJkiee",
        "outputId": "760d09d8-5f81-4012-9ddb-dc4cd157b59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data=Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[4488], edge_label_index=[2, 4488])\n",
            "val_data=Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[526], edge_label_index=[2, 526])\n",
            "test_data=Data(x=[2708, 1433], edge_index=[2, 9502], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[1054], edge_label_index=[2, 1054])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vspglpvho4g4",
        "outputId": "615d9b58-cd91-470c-d2b5-612f9de42cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((train_data.edge_label < 1).nonzero())\n",
        "print(train_data.edge_label_index)\n",
        "print(train_data.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiUCuWvqmrcP",
        "outputId": "d9d8232b-6a3d-471f-820d-55088c56cc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([], size=(0, 1), dtype=torch.int64)\n",
            "tensor([[ 415,  537, 2001,  ..., 1119,  483,  908],\n",
            "        [1843, 1165, 2348,  ..., 2126,  816, 1013]])\n",
            "tensor([3, 4, 4,  ..., 3, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
        "\n"
      ],
      "metadata": {
        "id": "_BtM50cAleI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Net(dataset.num_features, 128, 64).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ea8Ha6T_lgKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "z = model.encode(train_data.x, train_data.edge_index)\n",
        "\n",
        "# We perform a new round of negative sampling for every training epoch:\n",
        "neg_edge_index = negative_sampling(\n",
        "    edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
        "    num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
        "\n",
        "edge_label_index = torch.cat(\n",
        "    [train_data.edge_label_index, neg_edge_index],\n",
        "    dim=-1,\n",
        ")\n",
        "edge_label = torch.cat([\n",
        "    train_data.edge_label,\n",
        "    train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
        "], dim=0)\n",
        "\n",
        "out = model.decode(z, edge_label_index).view(-1)\n",
        "print(out)\n",
        "print(out.view(-1).sigmoid().shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyMyNzrSmNTX",
        "outputId": "9ad27a45-2740-4362-c727-f259a00edf53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0009, 0.0013, 0.0010,  ..., 0.0003, 0.0003, 0.0005],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "torch.Size([8976])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x, train_data.edge_index)\n",
        "\n",
        "    # We perform a new round of negative sampling for every training epoch:\n",
        "    neg_edge_index = negative_sampling(\n",
        "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
        "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
        "\n",
        "    edge_label_index = torch.cat(\n",
        "        [train_data.edge_label_index, neg_edge_index],\n",
        "        dim=-1,\n",
        "    )\n",
        "    edge_label = torch.cat([\n",
        "        train_data.edge_label,\n",
        "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
        "    ], dim=0)\n",
        "\n",
        "    out = model.decode(z, edge_label_index).view(-1)\n",
        "    loss = criterion(out, edge_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "jv6ZqtfFlj-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
        "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "5Yq8GOJ0lmij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_val_auc = final_test_auc = 0\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    val_auc = test(val_data)\n",
        "    test_auc = test(test_data)\n",
        "    if val_auc > best_val_auc:\n",
        "        best_val_auc = val_auc\n",
        "        final_test_auc = test_auc\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
        "          f'Test: {test_auc:.4f}')\n",
        "\n",
        "print(f'Final Test: {final_test_auc:.4f}')\n",
        "\n",
        "z = model.encode(test_data.x, test_data.edge_index)\n",
        "final_edge_index = model.decode_all(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KYdG8eDiuFi",
        "outputId": "6e01a90a-917e-4843-8394-bbd511607ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.6930, Val: 0.7511, Test: 0.6890\n",
            "Epoch: 002, Loss: 0.6819, Val: 0.7426, Test: 0.6810\n",
            "Epoch: 003, Loss: 0.7107, Val: 0.7487, Test: 0.6880\n",
            "Epoch: 004, Loss: 0.6780, Val: 0.7643, Test: 0.7071\n",
            "Epoch: 005, Loss: 0.6848, Val: 0.7848, Test: 0.7362\n",
            "Epoch: 006, Loss: 0.6887, Val: 0.8084, Test: 0.7555\n",
            "Epoch: 007, Loss: 0.6897, Val: 0.8063, Test: 0.7445\n",
            "Epoch: 008, Loss: 0.6893, Val: 0.7854, Test: 0.7229\n",
            "Epoch: 009, Loss: 0.6873, Val: 0.7707, Test: 0.7073\n",
            "Epoch: 010, Loss: 0.6832, Val: 0.7580, Test: 0.6979\n",
            "Epoch: 011, Loss: 0.6777, Val: 0.7493, Test: 0.6920\n",
            "Epoch: 012, Loss: 0.6753, Val: 0.7480, Test: 0.6921\n",
            "Epoch: 013, Loss: 0.6768, Val: 0.7487, Test: 0.6977\n",
            "Epoch: 014, Loss: 0.6697, Val: 0.7519, Test: 0.7084\n",
            "Epoch: 015, Loss: 0.6644, Val: 0.7580, Test: 0.7240\n",
            "Epoch: 016, Loss: 0.6594, Val: 0.7591, Test: 0.7324\n",
            "Epoch: 017, Loss: 0.6538, Val: 0.7556, Test: 0.7325\n",
            "Epoch: 018, Loss: 0.6445, Val: 0.7547, Test: 0.7337\n",
            "Epoch: 019, Loss: 0.6379, Val: 0.7701, Test: 0.7522\n",
            "Epoch: 020, Loss: 0.6267, Val: 0.7922, Test: 0.7848\n",
            "Epoch: 021, Loss: 0.6131, Val: 0.7974, Test: 0.7985\n",
            "Epoch: 022, Loss: 0.5991, Val: 0.7910, Test: 0.7967\n",
            "Epoch: 023, Loss: 0.5847, Val: 0.7937, Test: 0.7976\n",
            "Epoch: 024, Loss: 0.5687, Val: 0.7917, Test: 0.7927\n",
            "Epoch: 025, Loss: 0.5575, Val: 0.7830, Test: 0.7906\n",
            "Epoch: 026, Loss: 0.5554, Val: 0.7689, Test: 0.7833\n",
            "Epoch: 027, Loss: 0.5518, Val: 0.7766, Test: 0.7869\n",
            "Epoch: 028, Loss: 0.5458, Val: 0.7840, Test: 0.7901\n",
            "Epoch: 029, Loss: 0.5436, Val: 0.7878, Test: 0.7949\n",
            "Epoch: 030, Loss: 0.5473, Val: 0.7860, Test: 0.7980\n",
            "Epoch: 031, Loss: 0.5422, Val: 0.7915, Test: 0.8034\n",
            "Epoch: 032, Loss: 0.5296, Val: 0.8077, Test: 0.8133\n",
            "Epoch: 033, Loss: 0.5302, Val: 0.8169, Test: 0.8174\n",
            "Epoch: 034, Loss: 0.5280, Val: 0.8195, Test: 0.8191\n",
            "Epoch: 035, Loss: 0.5288, Val: 0.8190, Test: 0.8207\n",
            "Epoch: 036, Loss: 0.5169, Val: 0.8180, Test: 0.8218\n",
            "Epoch: 037, Loss: 0.5110, Val: 0.8206, Test: 0.8235\n",
            "Epoch: 038, Loss: 0.5097, Val: 0.8241, Test: 0.8262\n",
            "Epoch: 039, Loss: 0.5082, Val: 0.8247, Test: 0.8270\n",
            "Epoch: 040, Loss: 0.5097, Val: 0.8219, Test: 0.8247\n",
            "Epoch: 041, Loss: 0.5175, Val: 0.8221, Test: 0.8248\n",
            "Epoch: 042, Loss: 0.5046, Val: 0.8262, Test: 0.8279\n",
            "Epoch: 043, Loss: 0.4954, Val: 0.8315, Test: 0.8320\n",
            "Epoch: 044, Loss: 0.5075, Val: 0.8350, Test: 0.8344\n",
            "Epoch: 045, Loss: 0.4931, Val: 0.8365, Test: 0.8356\n",
            "Epoch: 046, Loss: 0.4979, Val: 0.8368, Test: 0.8358\n",
            "Epoch: 047, Loss: 0.4965, Val: 0.8407, Test: 0.8404\n",
            "Epoch: 048, Loss: 0.4982, Val: 0.8434, Test: 0.8439\n",
            "Epoch: 049, Loss: 0.4824, Val: 0.8464, Test: 0.8474\n",
            "Epoch: 050, Loss: 0.4903, Val: 0.8490, Test: 0.8517\n",
            "Epoch: 051, Loss: 0.4792, Val: 0.8489, Test: 0.8527\n",
            "Epoch: 052, Loss: 0.4875, Val: 0.8510, Test: 0.8566\n",
            "Epoch: 053, Loss: 0.4781, Val: 0.8555, Test: 0.8615\n",
            "Epoch: 054, Loss: 0.4721, Val: 0.8585, Test: 0.8639\n",
            "Epoch: 055, Loss: 0.4826, Val: 0.8600, Test: 0.8662\n",
            "Epoch: 056, Loss: 0.4758, Val: 0.8585, Test: 0.8670\n",
            "Epoch: 057, Loss: 0.4701, Val: 0.8598, Test: 0.8679\n",
            "Epoch: 058, Loss: 0.4782, Val: 0.8636, Test: 0.8699\n",
            "Epoch: 059, Loss: 0.4733, Val: 0.8656, Test: 0.8702\n",
            "Epoch: 060, Loss: 0.4765, Val: 0.8670, Test: 0.8705\n",
            "Epoch: 061, Loss: 0.4723, Val: 0.8684, Test: 0.8708\n",
            "Epoch: 062, Loss: 0.4727, Val: 0.8670, Test: 0.8709\n",
            "Epoch: 063, Loss: 0.4680, Val: 0.8658, Test: 0.8705\n",
            "Epoch: 064, Loss: 0.4613, Val: 0.8675, Test: 0.8713\n",
            "Epoch: 065, Loss: 0.4619, Val: 0.8697, Test: 0.8712\n",
            "Epoch: 066, Loss: 0.4683, Val: 0.8687, Test: 0.8707\n",
            "Epoch: 067, Loss: 0.4687, Val: 0.8673, Test: 0.8699\n",
            "Epoch: 068, Loss: 0.4739, Val: 0.8651, Test: 0.8693\n",
            "Epoch: 069, Loss: 0.4640, Val: 0.8672, Test: 0.8689\n",
            "Epoch: 070, Loss: 0.4647, Val: 0.8699, Test: 0.8691\n",
            "Epoch: 071, Loss: 0.4736, Val: 0.8702, Test: 0.8699\n",
            "Epoch: 072, Loss: 0.4699, Val: 0.8681, Test: 0.8706\n",
            "Epoch: 073, Loss: 0.4649, Val: 0.8665, Test: 0.8709\n",
            "Epoch: 074, Loss: 0.4675, Val: 0.8702, Test: 0.8724\n",
            "Epoch: 075, Loss: 0.4698, Val: 0.8733, Test: 0.8734\n",
            "Epoch: 076, Loss: 0.4600, Val: 0.8736, Test: 0.8744\n",
            "Epoch: 077, Loss: 0.4623, Val: 0.8713, Test: 0.8756\n",
            "Epoch: 078, Loss: 0.4559, Val: 0.8702, Test: 0.8764\n",
            "Epoch: 079, Loss: 0.4655, Val: 0.8715, Test: 0.8769\n",
            "Epoch: 080, Loss: 0.4629, Val: 0.8733, Test: 0.8786\n",
            "Epoch: 081, Loss: 0.4589, Val: 0.8749, Test: 0.8780\n",
            "Epoch: 082, Loss: 0.4595, Val: 0.8741, Test: 0.8785\n",
            "Epoch: 083, Loss: 0.4583, Val: 0.8719, Test: 0.8793\n",
            "Epoch: 084, Loss: 0.4657, Val: 0.8703, Test: 0.8789\n",
            "Epoch: 085, Loss: 0.4634, Val: 0.8709, Test: 0.8799\n",
            "Epoch: 086, Loss: 0.4614, Val: 0.8739, Test: 0.8802\n",
            "Epoch: 087, Loss: 0.4578, Val: 0.8741, Test: 0.8793\n",
            "Epoch: 088, Loss: 0.4559, Val: 0.8748, Test: 0.8802\n",
            "Epoch: 089, Loss: 0.4578, Val: 0.8756, Test: 0.8822\n",
            "Epoch: 090, Loss: 0.4581, Val: 0.8739, Test: 0.8821\n",
            "Epoch: 091, Loss: 0.4622, Val: 0.8736, Test: 0.8823\n",
            "Epoch: 092, Loss: 0.4595, Val: 0.8767, Test: 0.8827\n",
            "Epoch: 093, Loss: 0.4516, Val: 0.8775, Test: 0.8840\n",
            "Epoch: 094, Loss: 0.4575, Val: 0.8778, Test: 0.8859\n",
            "Epoch: 095, Loss: 0.4497, Val: 0.8788, Test: 0.8875\n",
            "Epoch: 096, Loss: 0.4510, Val: 0.8805, Test: 0.8889\n",
            "Epoch: 097, Loss: 0.4509, Val: 0.8821, Test: 0.8904\n",
            "Epoch: 098, Loss: 0.4508, Val: 0.8813, Test: 0.8917\n",
            "Epoch: 099, Loss: 0.4498, Val: 0.8828, Test: 0.8933\n",
            "Epoch: 100, Loss: 0.4463, Val: 0.8859, Test: 0.8949\n",
            "Final Test: 0.8949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(final_edge_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdw9rz5StUFR",
        "outputId": "5c47fc0b-9860-4606-ce1c-7f96d7c6954e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
            "        [   0,    1,    2,  ..., 2705, 2706, 2707]])\n"
          ]
        }
      ]
    }
  ]
}